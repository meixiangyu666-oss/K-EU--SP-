import streamlit as st
import pandas as pd
from collections import defaultdict
import re
import io
import uuid

# å‡½æ•°ï¼šä»è°ƒç ” Excel ç”Ÿæˆè¡¨å¤´ Excel
def generate_header_from_survey(df_survey, output_file='header-K EU.xlsx'):
    print(f"æˆåŠŸè¯»å–æ•°æ®ï¼Œæ•°æ®å½¢çŠ¶ï¼š{df_survey.shape}")
    print(f"åˆ—ååˆ—è¡¨: {list(df_survey.columns)}")
    
    # æå–ç‹¬ç‰¹æ´»åŠ¨åç§°
    unique_campaigns = [name for name in df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'].dropna() if str(name).strip()]
    print(f"ç‹¬ç‰¹æ´»åŠ¨åç§°æ•°é‡: {len(unique_campaigns)}: {unique_campaigns}")
    
    # åˆ›å»ºæ´»åŠ¨åˆ° CPC/SKU/å¹¿å‘Šç»„é»˜è®¤ç«ä»·/é¢„ç®— çš„æ˜ å°„
    non_empty_campaigns = df_survey[
        df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'].notna() & 
        (df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'] != '')
    ]
    required_cols = ['CPC', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·', 'é¢„ç®—']
    if all(col in non_empty_campaigns.columns for col in required_cols):
        campaign_to_values = non_empty_campaigns.drop_duplicates(
            subset='å¹¿å‘Šæ´»åŠ¨åç§°', keep='first'
        ).set_index('å¹¿å‘Šæ´»åŠ¨åç§°')[required_cols].to_dict('index')
    else:
        campaign_to_values = {}
        print(f"è­¦å‘Šï¼šç¼ºå°‘åˆ— {set(required_cols) - set(non_empty_campaigns.columns)}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    print(f"ç”Ÿæˆçš„å­—å…¸ï¼ˆæœ‰ {len(campaign_to_values)} ä¸ªæ´»åŠ¨ï¼‰: {campaign_to_values}")
    
    # å…³é”®è¯åˆ—ï¼šç¬¬ H åˆ—ï¼ˆç´¢å¼• 7ï¼‰åˆ°ç¬¬ Q åˆ—ï¼ˆç´¢å¼• 16ï¼‰
    keyword_columns = df_survey.columns[7:17]
    print(f"å…³é”®è¯åˆ—: {list(keyword_columns)}")
    
    # æ£€æŸ¥å…³é”®è¯é‡å¤
    duplicates_found = False
    print("\n=== æ£€æŸ¥å…³é”®è¯é‡å¤ ===")
    for col in keyword_columns:
        col_index = list(df_survey.columns).index(col) + 1
        col_letter = chr(64 + col_index) if col_index <= 26 else f"{chr(64 + (col_index-1)//26)}{chr(64 + (col_index-1)%26 + 1)}"
        kw_list = [kw for kw in df_survey[col].dropna() if str(kw).strip()]
        
        if len(kw_list) > len(set(kw_list)):
            duplicates_mask = df_survey[col].duplicated(keep=False)
            duplicates_df = df_survey[duplicates_mask][[col]].dropna()
            print(f"è­¦å‘Šï¼š{col_letter} åˆ— ({col}) æœ‰é‡å¤å…³é”®è¯")
            for _, row in duplicates_df.iterrows():
                kw = str(row[col]).strip()
                count = (df_survey[col] == kw).sum()
                if count > 1:
                    print(f"  é‡å¤è¯: '{kw}' (å‡ºç° {count} æ¬¡)")
            duplicates_found = True
    
    if duplicates_found:
        st.error("æ£€æµ‹åˆ°å…³é”®è¯é‡å¤ï¼Œè¯·æ¸…ç†é‡å¤å…³é”®è¯åé‡è¯•ã€‚")
        return None
    
    print("å…³é”®è¯æ— é‡å¤ï¼Œç»§ç»­ç”Ÿæˆ...")
    
    # åˆ—å®šä¹‰
    columns = [
        'äº§å“', 'å®ä½“å±‚çº§', 'æ“ä½œ', 'å¹¿å‘Šæ´»åŠ¨ç¼–å·', 'å¹¿å‘Šç»„ç¼–å·', 'å¹¿å‘Šç»„åˆç¼–å·', 'å¹¿å‘Šç¼–å·', 'å…³é”®è¯ç¼–å·', 'å•†å“æŠ•æ”¾ ID',
        'å¹¿å‘Šæ´»åŠ¨åç§°', 'å¹¿å‘Šç»„åç§°', 'å¼€å§‹æ—¥æœŸ', 'ç»“æŸæ—¥æœŸ', 'æŠ•æ”¾ç±»å‹', 'çŠ¶æ€', 'æ¯æ—¥é¢„ç®—', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·',
        'ç«ä»·', 'å…³é”®è¯æ–‡æœ¬', 'åŒ¹é…ç±»å‹', 'ç«ä»·æ–¹æ¡ˆ', 'å¹¿å‘Šä½', 'ç™¾åˆ†æ¯”', 'æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·'
    ]
    
    # é»˜è®¤å€¼
    product = 'å•†å“æ¨å¹¿'
    operation = 'Create'
    status = 'å·²å¯ç”¨'
    targeting_type = 'æ‰‹åŠ¨'
    bidding_strategy = 'åŠ¨æ€ç«ä»· - ä»…é™ä½'
    default_daily_budget = 12
    default_group_bid = 0.6
    
    # ä»åˆ—åä¸­æå–æ‰€æœ‰å¯èƒ½çš„å…³é”®è¯ç±»åˆ«
    keyword_categories = set()
    for col in df_survey.columns:
        col_lower = str(col).lower()
        if 'asin' in col_lower and 'å¦å®š' not in col_lower:
            # ä»åˆ—åä¸­æå–å…³é”®è¯ç±»åˆ«
            for suffix in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯', 'ç²¾å‡†', 'å¹¿æ³›', 'asin']:
                if col_lower.endswith(suffix):
                    prefix = col_lower[:-len(suffix)].strip()
                    if prefix:
                        if '/' in prefix:
                            parts = [p.strip() for p in prefix.split('/') if p.strip()]
                            keyword_categories.update(parts)
                        else:
                            keyword_categories.add(prefix)
                    break
    # æ·»åŠ å·²çŸ¥çš„å…³é”®è¯ç±»åˆ«ï¼ˆæ·»åŠ  'host' ä»¥åŒ¹é…æ´»åŠ¨åï¼‰
    keyword_categories.update(['suzhu', 'host', 'å®¿ä¸»', 'case', 'åŒ…', 'tape'])
    # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
    keyword_categories = {cat for cat in keyword_categories if cat.strip()}
    
    print(f"è¯†åˆ«åˆ°çš„å…³é”®è¯ç±»åˆ«: {keyword_categories}")
    
    # ç”Ÿæˆæ•°æ®è¡Œ
    rows = []
    
    for campaign_name in unique_campaigns:
        # è·å– CPCã€SKUã€å¹¿å‘Šç»„é»˜è®¤ç«ä»·ã€é¢„ç®—
        if campaign_name in campaign_to_values:
            cpc = campaign_to_values[campaign_name]['CPC']
            sku = campaign_to_values[campaign_name]['SKU']
            group_bid = campaign_to_values[campaign_name]['å¹¿å‘Šç»„é»˜è®¤ç«ä»·']
            budget = campaign_to_values[campaign_name]['é¢„ç®—']
        else:
            cpc = 0.5
            sku = 'SKU-1'
            group_bid = default_group_bid
            budget = default_daily_budget
        
        print(f"å¤„ç†æ´»åŠ¨: {campaign_name}")
        
        campaign_name_normalized = str(campaign_name).lower()
        
        # æ’åºç±»åˆ«ï¼ŒæŒ‰é•¿åº¦å‡åºï¼ˆä¼˜å…ˆçŸ­ç±»åˆ«å¦‚ 'host'ï¼‰
        sorted_categories = sorted(keyword_categories, key=len)
        
        # åŠ¨æ€æå–å…³é”®è¯ç±»åˆ«ï¼ˆç°åœ¨è¿‡æ»¤ç©ºä¸²ï¼Œæ·»åŠ  hostï¼‰
        matched_category = None
        for category in sorted_categories:
            if category in campaign_name_normalized:
                matched_category = category
                break
        
        print(f"  åŒ¹é…çš„å…³é”®è¯ç±»åˆ«: {matched_category}")
        
        # ç¡®å®šåŒ¹é…ç±»å‹
        is_exact = any(x in campaign_name_normalized for x in ['ç²¾å‡†', 'exact'])
        is_broad = any(x in campaign_name_normalized for x in ['å¹¿æ³›', 'broad'])
        is_asin = 'asin' in campaign_name_normalized
        match_type = 'ç²¾å‡†' if is_exact else 'å¹¿æ³›' if is_broad else 'ASIN' if is_asin else None
        print(f"  is_exact: {is_exact}, is_broad: {is_broad}, is_asin: {is_asin}, match_type: {match_type}")
        
        # æå–å…³é”®è¯ï¼ˆç”¨äºæ­£å‘å…³é”®è¯ï¼Œç²¾å‡†/å¹¿æ³›åŒ¹é…ï¼‰
        keywords = []
        matched_columns = []
        if matched_category and (is_exact or is_broad):
            for col in keyword_columns:
                col_lower = str(col).lower()
                if is_exact and matched_category in col_lower and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                    matched_columns.append(col)
                    keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
                elif is_broad and matched_category in col_lower and any(x in col_lower for x in ['å¹¿æ³›', 'broad']):
                    matched_columns.append(col)
                    keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
            keywords = list(dict.fromkeys(keywords))
            print(f"  åŒ¹é…çš„åˆ—: {matched_columns}")
            print(f"  å…³é”®è¯æ•°é‡: {len(keywords)} (ç¤ºä¾‹: {keywords[:2] if keywords else 'æ— '})")
        else:
            print("  æ— åŒ¹é…çš„å…³é”®è¯åˆ—ï¼Œå…³é”®è¯ä¸ºç©º")
        
        # æå– ASINï¼ˆç”¨äºå•†å“å®šå‘ï¼‰
        asin_targets = []
        if is_asin:
            # ç²¾ç¡®åŒ¹é…ï¼šåˆ—åå¿…é¡»ä¸å¹¿å‘Šæ´»åŠ¨åç§°å®Œå…¨ä¸€è‡´
            if campaign_name in df_survey.columns:
                asin_targets.extend([asin for asin in df_survey[campaign_name].dropna() if str(asin).strip()])
                print(f"  æ‰¾åˆ°ä¸æ´»åŠ¨åç§°å®Œå…¨åŒ¹é…çš„åˆ—: {campaign_name}")
            else:
                print(f"  æœªæ‰¾åˆ°ä¸æ´»åŠ¨åç§°å®Œå…¨åŒ¹é…çš„åˆ—: {campaign_name}")
            asin_targets = list(dict.fromkeys(asin_targets))
            print(f"  å•†å“å®šå‘ ASIN æ•°é‡: {len(asin_targets)} (ç¤ºä¾‹: {asin_targets[:2] if asin_targets else 'æ— '})")
        
        # æ–°å¢ï¼šç«ä»·è°ƒæ•´è¡Œï¼ˆæ¯æ¡æ´»åŠ¨ä¸€æ¡ï¼‰
        placement_value = "å¹¿å‘Šä½ï¼šå•†å“é¡µé¢" if is_asin else "å¹¿å‘Šä½ï¼šæœç´¢ç»“æœé¦–é¡µé¦–ä½"
        bid_adjustment_row = [
            product, 'ç«ä»·è°ƒæ•´', operation, campaign_name, '', '', '', '', '',
            campaign_name, campaign_name, '', '', targeting_type, '', '', '', '',
            '', '', '', bidding_strategy, placement_value, '900', ''
        ]
        rows.append(bid_adjustment_row)
        print(f"  æ·»åŠ ç«ä»·è°ƒæ•´è¡Œ: å¹¿å‘Šä½={placement_value}")
        
        # å¹¿å‘Šæ´»åŠ¨è¡Œ
        rows.append([
            product, 'å¹¿å‘Šæ´»åŠ¨', operation, campaign_name, '', '', '', '', '',
            campaign_name, '', '', '', targeting_type, status, budget, '', '',
            '', '', '', bidding_strategy, '', '', ''
        ])
        
        # å¹¿å‘Šç»„è¡Œ
        rows.append([
            product, 'å¹¿å‘Šç»„', operation, campaign_name, campaign_name, '', '', '', '',
            campaign_name, campaign_name, '', '', '', status, '', '', group_bid,
            '', '', '', '', '', '', ''
        ])
        
        # å•†å“å¹¿å‘Šè¡Œ
        rows.append([
            product, 'å•†å“å¹¿å‘Š', operation, campaign_name, campaign_name, '', '', '', '',
            campaign_name, campaign_name, '', '', '', status, '', sku, '',
            '', '', '', '', '', '', ''
        ])
        
        # å…³é”®è¯è¡Œï¼ˆä»…ç²¾å‡†/å¹¿æ³›åŒ¹é…ï¼‰
        if is_exact or is_broad:
            for kw in keywords:
                rows.append([
                    product, 'å…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '',
                    cpc, kw, match_type, '', '', '', ''
                ])
        
        # ä¿®æ”¹åçš„å¦å®šå…³é”®è¯è§„åˆ™
        neg_exact = []
        neg_phrase = []
        
        if is_broad:
            # å¹¿æ³›ç»„ï¼šSåˆ—ï¼ˆå¦å®šç²¾å‡†ï¼‰ï¼ŒTåˆ—ï¼ˆå¦å®šè¯ç»„ï¼‰
            s_col = df_survey.iloc[:, 18]  # Såˆ— (index 18)
            t_col = df_survey.iloc[:, 19]  # Tåˆ— (index 19)
            neg_exact = [kw for kw in s_col.dropna() if str(kw).strip()]
            neg_phrase = [kw for kw in t_col.dropna() if str(kw).strip()]
            neg_exact = list(dict.fromkeys(neg_exact))
            neg_phrase = list(dict.fromkeys(neg_phrase))
            print(f"  å¹¿æ³›ç»„å¦å®šï¼šç²¾å‡† {len(neg_exact)} ä¸ªï¼Œè¯ç»„ {len(neg_phrase)} ä¸ª")
        elif is_exact and matched_category:
            # ç²¾å‡†ç»„ï¼šæ ¹æ®ç±»åˆ«
            if matched_category in ['suzhu', 'host', 'å®¿ä¸»']:
                # å®¿ä¸»ç²¾å‡†ç»„ï¼šUåˆ—ï¼ˆå¦å®šç²¾å‡†ï¼‰ï¼ŒVåˆ—ï¼ˆå¦å®šè¯ç»„ï¼‰
                u_col = df_survey.iloc[:, 20]  # Uåˆ— (index 20)
                v_col = df_survey.iloc[:, 21]  # Våˆ— (index 21)
                neg_exact = [kw for kw in u_col.dropna() if str(kw).strip()]
                neg_phrase = [kw for kw in v_col.dropna() if str(kw).strip()]
            elif matched_category == 'case':
                # caseç²¾å‡†ç»„ï¼šWåˆ—ï¼ˆå¦å®šç²¾å‡†ï¼‰ï¼ŒXåˆ—ï¼ˆå¦å®šè¯ç»„ï¼‰
                w_col = df_survey.iloc[:, 22]  # Wåˆ— (index 22)
                x_col = df_survey.iloc[:, 23]  # Xåˆ— (index 23)
                neg_exact = [kw for kw in w_col.dropna() if str(kw).strip()]
                neg_phrase = [kw for kw in x_col.dropna() if str(kw).strip()]
            neg_exact = list(dict.fromkeys(neg_exact))
            neg_phrase = list(dict.fromkeys(neg_phrase))
            print(f"  {matched_category}ç²¾å‡†ç»„å¦å®šï¼šç²¾å‡† {len(neg_exact)} ä¸ªï¼Œè¯ç»„ {len(neg_phrase)} ä¸ª")
        
        # å¦å®šå…³é”®è¯è¡Œï¼ˆä»…ç²¾å‡†/å¹¿æ³›åŒ¹é…ï¼‰
        if is_exact or is_broad:
            for kw in neg_exact:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                ])
            for kw in neg_phrase:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šè¯ç»„', '', '', '', ''
                ])
        
        # å•†å“å®šå‘å’Œå¦å®šå•†å“å®šå‘ï¼ˆä»… ASIN ç»„ï¼‰
        neg_asin = [kw for kw in df_survey.get('å¦å®šASIN', pd.Series()).dropna() if str(kw).strip()]
        if is_asin:
            for asin in asin_targets:
                rows.append([
                    product, 'å•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '',
                    cpc, '', '', '', '', '', f'asin="{asin}"'
                ])
            for asin in neg_asin:
                rows.append([
                    product, 'å¦å®šå•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '',
                    '', '', '', '', '', '', f'asin="{asin}"'
                ])
    
    # åˆ›å»º DataFrame
    df_header = pd.DataFrame(rows, columns=columns)
    
    # ä½¿ç”¨ BytesIO ä¿å­˜åˆ°å†…å­˜
    output_buffer = io.BytesIO()
    with pd.ExcelWriter(output_buffer, engine='openpyxl') as writer:
        df_header.to_excel(writer, index=False, sheet_name='Sheet1')
    output_buffer.seek(0)
    
    print(f"ç”Ÿæˆå®Œæˆï¼æ€»è¡Œæ•°ï¼š{len(rows)}")
    
    # è°ƒè¯•è¾“å‡º
    keyword_rows = [row for row in rows if row[1] == 'å…³é”®è¯']
    print(f"å…³é”®è¯è¡Œæ•°é‡: {len(keyword_rows)}")
    if keyword_rows:
        print(f"ç¤ºä¾‹å…³é”®è¯è¡Œ: å®ä½“å±‚çº§={keyword_rows[0][1]}, å…³é”®è¯æ–‡æœ¬={keyword_rows[0][19]}, åŒ¹é…ç±»å‹={keyword_rows[0][20]}")
    
    product_targeting_rows = [row for row in rows if row[1] == 'å•†å“å®šå‘']
    print(f"å•†å“å®šå‘è¡Œæ•°é‡: {len(product_targeting_rows)}")
    if product_targeting_rows:
        print(f"ç¤ºä¾‹å•†å“å®šå‘è¡Œ: å®ä½“å±‚çº§={product_targeting_rows[0][1]}, ç«ä»·={product_targeting_rows[0][18]}, æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·={product_targeting_rows[0][24]}")
    
    bid_adjustment_rows = [row for row in rows if row[1] == 'ç«ä»·è°ƒæ•´']
    print(f"ç«ä»·è°ƒæ•´è¡Œæ•°é‡: {len(bid_adjustment_rows)}")
    if bid_adjustment_rows:
        print(f"ç¤ºä¾‹ç«ä»·è°ƒæ•´è¡Œ: å®ä½“å±‚çº§={bid_adjustment_rows[0][1]}, å¹¿å‘Šä½={bid_adjustment_rows[0][22]}, ç™¾åˆ†æ¯”={bid_adjustment_rows[0][23]}")
    
    levels = set(row[1] for row in rows)
    print(f"æ‰€æœ‰å®ä½“å±‚çº§: {levels}")
    
    return output_buffer

# Streamlit åº”ç”¨
st.set_page_config(page_title="K EU å°èµ–ç‰ˆ-SPå¹¿å‘Šæ‰¹é‡æ¨¡ç‰ˆå·¥å…·", page_icon="ğŸš€", layout="wide")

st.title("ğŸš€ K EU å°èµ–ç‰ˆ-SPå¹¿å‘Šæ‰¹é‡æ¨¡ç‰ˆå·¥å…·")

st.markdown("""
### åŒ¹é…è§„åˆ™è¯´æ˜
æœ¬å·¥å…·åŸºäºè°ƒç ”Excelæ–‡ä»¶ç”ŸæˆSPå¹¿å‘Šæ‰¹é‡æ¨¡æ¿ï¼ˆheader-K EU.xlsxï¼‰ã€‚ä»¥ä¸‹æ˜¯æ ¸å¿ƒåŒ¹é…è§„åˆ™ï¼š

1. **æ´»åŠ¨åç§°åŒ¹é…**ï¼š
   - ä»'å¹¿å‘Šæ´»åŠ¨åç§°'åˆ—æå–ç‹¬ç‰¹æ´»åŠ¨ã€‚
   - åŒ¹é…ç±»å‹ï¼šæ´»åŠ¨åå«'ç²¾å‡†'æˆ–'exact' â†’ ç²¾å‡†åŒ¹é…ï¼›å«'å¹¿æ³›'æˆ–'broad' â†’ å¹¿æ³›åŒ¹é…ï¼›å«'asin' â†’ ASINï¼ˆå•†å“å®šå‘ï¼‰ã€‚
   - å…³é”®è¯ç±»åˆ«ï¼šä»æ´»åŠ¨ååŒ¹é…å·²çŸ¥ç±»åˆ«ï¼ˆå¦‚'suzhu'ã€'host'ã€'å®¿ä¸»'ã€'case'ã€'åŒ…'ã€'tape'ï¼‰ï¼Œæˆ–ä»åˆ—åå‰ç¼€åŠ¨æ€æå–ï¼ˆH-Qåˆ—ï¼‰ã€‚

2. **å…³é”®è¯æå–**ï¼š
   - ç²¾å‡†/å¹¿æ³›ï¼šä»H-Qåˆ—åŒ¹é…ç±»åˆ«+åŒ¹é…ç±»å‹ï¼ˆå¦‚'hostç²¾å‡†'åˆ—ï¼‰æå–å…³é”®è¯ï¼ˆå»é‡ï¼‰ã€‚
   - ASINï¼šæ´»åŠ¨åä½œä¸ºåˆ—åç²¾ç¡®åŒ¹é…ï¼Œæå–ASINåˆ—è¡¨ã€‚

3. **å¦å®šå…³é”®è¯**ï¼š
   - å¹¿æ³›ç»„ï¼šSåˆ—ï¼ˆå¦å®šç²¾å‡†ï¼‰ã€Tåˆ—ï¼ˆå¦å®šè¯ç»„ï¼‰ã€‚
   - ç²¾å‡†ç»„ï¼šæ ¹æ®ç±»åˆ«ï¼ˆå¦‚'host' â†’ U/Våˆ—ï¼›'case' â†’ W/Xåˆ—ï¼‰ã€‚
   - å¦å®šASINï¼šä»'å¦å®šASIN'åˆ—æå–ã€‚

4. **é»˜è®¤å€¼ä¸ç»“æ„**ï¼š
   - CPC/SKU/é¢„ç®—/ç«ä»·ï¼šä»è°ƒç ”åˆ—å–å€¼ï¼Œå¦åˆ™é»˜è®¤ï¼ˆCPC=0.5, é¢„ç®—=12, ç»„ç«ä»·=0.6ï¼‰ã€‚
   - æ¯æ´»åŠ¨ç”Ÿæˆï¼šç«ä»·è°ƒæ•´ï¼ˆé¦–é¡µé¦–ä½/å•†å“é¡µé¢ï¼Œ+900%ï¼‰ã€æ´»åŠ¨ã€ç»„ã€å•†å“å¹¿å‘Šã€å…³é”®è¯/å•†å“å®šå‘ã€å¦å®šé¡¹ã€‚
   - æ£€æŸ¥é‡å¤ï¼šH-Qåˆ—å…³é”®è¯é‡å¤å°†æŠ¥é”™ã€‚

5. **åˆ—è¦æ±‚**ï¼š
   - å¿…é¡»ï¼š'å¹¿å‘Šæ´»åŠ¨åç§°'ã€CPC/SKU/å¹¿å‘Šç»„é»˜è®¤ç«ä»·/é¢„ç®—ï¼ˆå¯é€‰ï¼Œé»˜è®¤å€¼ï¼‰ã€‚
   - å…³é”®è¯ï¼šH-Qåˆ—ï¼ˆç´¢å¼•7-16ï¼‰ã€‚
   - å¦å®šï¼šS-Xåˆ—ï¼ˆç´¢å¼•18-23ï¼‰ã€‚

ä¸Šä¼ è°ƒç ”Excelï¼ˆé»˜è®¤ç¬¬ä¸€ä¸ªSheetï¼‰ï¼Œç‚¹å‡»ç”Ÿæˆä¸‹è½½æ¨¡æ¿ï¼
""")

uploaded_file = st.file_uploader("ä¸Šä¼ è°ƒç ”Excelæ–‡ä»¶", type=['xlsx', 'xls'])

if uploaded_file is not None:
    try:
        df_survey = pd.read_excel(uploaded_file, sheet_name=0)
        st.success(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å½¢çŠ¶ï¼š{df_survey.shape}")
        st.dataframe(df_survey.head(), use_container_width=True)
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å‡ºé”™ï¼š{e}")
        st.stop()

if st.button("ç”Ÿæˆè¡¨å¤´", type="primary"):
    if 'df_survey' not in locals():
        st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")
    else:
        with st.spinner("æ­£åœ¨ç”Ÿæˆè¡¨å¤´..."):
            output_buffer = generate_header_from_survey(df_survey)
            if output_buffer is not None:
                st.success("ç”Ÿæˆå®Œæˆï¼")
                st.download_button(
                    label="ä¸‹è½½ header-K EU.xlsx",
                    data=output_buffer.getvalue(),
                    file_name="header-K EU.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.error("ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")