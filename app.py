import streamlit as st
import pandas as pd
from collections import defaultdict
import re
import os

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="K EU å°èµ–ç‰ˆ-SPå¹¿å‘Šæ‰¹é‡æ¨¡ç‰ˆå·¥å…·", page_icon="ğŸ“Š", layout="centered")

# è‡ªå®šä¹‰ CSS æ ·å¼
st.markdown("""
    <style>
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-size: 2.5em;
        font-weight: bold;
        color: #2C3E50;
        text-align: center;
        margin-bottom: 20px;
    }
    /* è§„åˆ™è¯´æ˜æ ·å¼ */
    .rules {
        font-size: 0.9em;
        color: #34495E;
        background-color: #F8F9FA;
        padding: 15px;
        border-radius: 8px;
        margin-bottom: 20px;
    }
    /* æŒ‰é’®æ ·å¼ */
    .stButton>button {
        background-color: #3498DB;
        color: white;
        border-radius: 8px;
        padding: 10px 20px;
        font-size: 1em;
        font-weight: bold;
    }
    .stButton>button:hover {
        background-color: #2980B9;
    }
    /* æ–‡ä»¶ä¸Šä¼ æ¡†æ ·å¼ */
    .stFileUploader label {
        font-size: 1.1em;
        color: #2C3E50;
        font-weight: bold;
    }
    /* æˆåŠŸå’Œé”™è¯¯æ¶ˆæ¯æ ·å¼ */
    .stSuccess {
        background-color: #E8F5E9;
        border-left: 5px solid #4CAF50;
        padding: 10px;
        border-radius: 5px;
    }
    .stError {
        background-color: #FFEBEE;
        border-left: 5px solid #F44336;
        padding: 10px;
        border-radius: 5px;
    }
    .stWarning {
        background-color: #FFF3E0;
        border-left: 5px solid #FF9800;
        padding: 10px;
        border-radius: 5px;
    }
    </style>
""", unsafe_allow_html=True)

# è§„åˆ™è¯´æ˜
st.markdown('<div class="main-title">K EU å°èµ–ç‰ˆ-SPå¹¿å‘Šæ‰¹é‡æ¨¡ç‰ˆå·¥å…·</div>', unsafe_allow_html=True)
st.markdown("""
<div class="rules">
<b>ä½¿ç”¨è§„åˆ™ / Usage Rules:</b><br>
1. ä¸Šä¼ ä»»æ„ .xlsx æ–‡ä»¶ï¼ˆæ–‡ä»¶åä¸é™ï¼‰ï¼Œéœ€åŒ…å« "å¹¿å‘Šæ´»åŠ¨åç§°"ã€"CPC"ã€"SKU"ã€"å¹¿å‘Šç»„é»˜è®¤ç«ä»·"ã€"é¢„ç®—" åˆ—ã€‚<br>
2. H-Q åˆ—ä¸ºå…³é”®è¯åˆ—ï¼ˆç²¾å‡†/å¹¿æ³›ï¼‰ã€‚<br>
3. æ”¯æŒç²¾å‡†/å¹¿æ³›/ASIN æ´»åŠ¨ï¼Œè‡ªåŠ¨ç”Ÿæˆå¦å®šå…³é”®è¯å’Œå•†å“å®šå‘ã€‚<br>
4. è¾“å‡ºæ–‡ä»¶: header-K EU.xlsxï¼ˆåŒ…å«å¹¿å‘Šæ´»åŠ¨ã€å¹¿å‘Šç»„ã€å…³é”®è¯ã€å¦å®šå…³é”®è¯ã€å•†å“å®šå‘ç­‰ï¼‰ã€‚<br>
5. å¦‚æœ‰é‡å¤å…³é”®è¯ï¼Œç”Ÿæˆä¸­æ­¢ï¼Œè¯·æ¸…ç†åé‡è¯•ã€‚<br><br>
<b>Upload any .xlsx file (filename flexible), must include "å¹¿å‘Šæ´»åŠ¨åç§°", "CPC", "SKU", "å¹¿å‘Šç»„é»˜è®¤ç«ä»·", "é¢„ç®—" columns.</b><br>
<b>H-Q columns for keywords (exact/broad).</b><br>
<b>Supports exact/broad/ASIN campaigns, auto-generates negatives and product targeting.</b><br>
<b>Output: header-K EU.xlsx (includes campaigns, groups, keywords, negatives, product targeting).</b><br>
<b>If duplicate keywords, generation stops; clean and retry.</b>
</div>
""", unsafe_allow_html=True)

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶ (ä»»æ„ .xlsx)", type=["xlsx"])

if uploaded_file is not None:
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    with open("temp_survey.xlsx", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # è¿è¡ŒæŒ‰é’®
    if st.button("ç”Ÿæˆ Header æ–‡ä»¶"):
        output_file = 'header-K EU.xlsx'
        with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶..."):
            result = generate_header_from_survey("temp_survey.xlsx", output_file)
            if result and os.path.exists(result):
                with open(result, "rb") as f:
                    st.download_button(
                        label="ä¸‹è½½ header-K EU.xlsx",
                        data=f,
                        file_name="header-K EU.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                st.success("ç”ŸæˆæˆåŠŸï¼è¯·ä¸‹è½½æ–‡ä»¶ã€‚")
            else:
                st.error("ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")

# script-K EU.py çš„å‡½æ•°
def generate_header_from_survey(survey_file='temp_survey.xlsx', output_file='header-K EU.xlsx', sheet_name=0):
    try:
        # è¯»å– Excel æ–‡ä»¶
        df_survey = pd.read_excel(survey_file, sheet_name=sheet_name)
        st.write(f"æˆåŠŸè¯»å–æ–‡ä»¶ï¼Œæ•°æ®å½¢çŠ¶ï¼š{df_survey.shape}")
        st.write(f"åˆ—ååˆ—è¡¨: {list(df_survey.columns)}")
    except FileNotFoundError:
        st.error(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ {survey_file}ã€‚")
        return None
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")
        return None
    
    # æå–ç‹¬ç‰¹æ´»åŠ¨åç§°
    unique_campaigns = [name for name in df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'].dropna() if str(name).strip()]
    st.write(f"ç‹¬ç‰¹æ´»åŠ¨åç§°æ•°é‡: {len(unique_campaigns)}: {unique_campaigns}")
    
    # åˆ›å»ºæ´»åŠ¨åˆ° CPC/SKU/å¹¿å‘Šç»„é»˜è®¤ç«ä»·/é¢„ç®— çš„æ˜ å°„
    non_empty_campaigns = df_survey[
        df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'].notna() & 
        (df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'] != '')
    ]
    required_cols = ['CPC', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·', 'é¢„ç®—']
    if all(col in non_empty_campaigns.columns for col in required_cols):
        campaign_to_values = non_empty_campaigns.drop_duplicates(
            subset='å¹¿å‘Šæ´»åŠ¨åç§°', keep='first'
        ).set_index('å¹¿å‘Šæ´»åŠ¨åç§°')[required_cols].to_dict('index')
    else:
        campaign_to_values = {}
        st.warning(f"è­¦å‘Šï¼šç¼ºå°‘åˆ— {set(required_cols) - set(non_empty_campaigns.columns)}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    st.write(f"ç”Ÿæˆçš„å­—å…¸ï¼ˆæœ‰ {len(campaign_to_values)} ä¸ªæ´»åŠ¨ï¼‰: {campaign_to_values}")
    
    # å…³é”®è¯åˆ—ï¼šç¬¬ H åˆ—ï¼ˆç´¢å¼• 7ï¼‰åˆ°ç¬¬ Q åˆ—ï¼ˆç´¢å¼• 16ï¼‰
    keyword_columns = df_survey.columns[7:17]
    st.write(f"å…³é”®è¯åˆ—: {list(keyword_columns)}")
    
    # æ£€æŸ¥å…³é”®è¯é‡å¤
    duplicates_found = False
    st.write("### æ£€æŸ¥å…³é”®è¯é‡å¤")
    for col in keyword_columns:
        col_index = list(df_survey.columns).index(col) + 1
        col_letter = chr(64 + col_index) if col_index <= 26 else f"{chr(64 + (col_index-1)//26)}{chr(64 + (col_index-1)%26 + 1)}"
        kw_list = [kw for kw in df_survey[col].dropna() if str(kw).strip()]
        
        if len(kw_list) > len(set(kw_list)):
            duplicates_mask = df_survey[col].duplicated(keep=False)
            duplicates_df = df_survey[duplicates_mask][[col]].dropna()
            st.warning(f"è­¦å‘Šï¼š{col_letter} åˆ— ({col}) æœ‰é‡å¤å…³é”®è¯")
            for _, row in duplicates_df.iterrows():
                kw = str(row[col]).strip()
                count = (df_survey[col] == kw).sum()
                if count > 1:
                    st.write(f"  é‡å¤è¯: '{kw}' (å‡ºç° {count} æ¬¡)")
            duplicates_found = True
    
    if duplicates_found:
        st.error("æç¤ºï¼šç”±äºæ£€æµ‹åˆ°å…³é”®è¯é‡å¤ï¼Œæœ¬æ¬¡ä¸ç”Ÿæˆè¡¨æ ¼ã€‚è¯·æ¸…ç†é‡å¤åé‡è¯•ã€‚")
        return None
    
    st.write("å…³é”®è¯æ— é‡å¤ï¼Œç»§ç»­ç”Ÿæˆ...")
    
    # åˆ—å®šä¹‰
    columns = [
        'äº§å“', 'å®ä½“å±‚çº§', 'æ“ä½œ', 'å¹¿å‘Šæ´»åŠ¨ç¼–å·', 'å¹¿å‘Šç»„ç¼–å·', 'å¹¿å‘Šç»„åˆç¼–å·', 'å¹¿å‘Šç¼–å·', 'å…³é”®è¯ç¼–å·', 'å•†å“æŠ•æ”¾ ID',
        'å¹¿å‘Šæ´»åŠ¨åç§°', 'å¹¿å‘Šç»„åç§°', 'å¼€å§‹æ—¥æœŸ', 'ç»“æŸæ—¥æœŸ', 'æŠ•æ”¾ç±»å‹', 'çŠ¶æ€', 'æ¯æ—¥é¢„ç®—', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·',
        'ç«ä»·', 'å…³é”®è¯æ–‡æœ¬', 'åŒ¹é…ç±»å‹', 'ç«ä»·æ–¹æ¡ˆ', 'å¹¿å‘Šä½', 'ç™¾åˆ†æ¯”', 'æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·'
    ]
    
    # é»˜è®¤å€¼
    product = 'å•†å“æ¨å¹¿'
    operation = 'Create'
    status = 'å·²å¯ç”¨'
    targeting_type = 'æ‰‹åŠ¨'
    bidding_strategy = 'åŠ¨æ€ç«ä»· - ä»…é™ä½'
    default_daily_budget = 12
    default_group_bid = 0.6
    
    # ä»åˆ—åä¸­æå–æ‰€æœ‰å¯èƒ½çš„å…³é”®è¯ç±»åˆ«
    keyword_categories = set()
    for col in df_survey.columns:
        col_lower = str(col).lower()
        if 'asin' in col_lower and 'å¦å®š' not in col_lower:
            # æå– ASIN åˆ—å‰ç¼€ä½œä¸ºç±»åˆ«
            prefix = col_lower.replace('asin', '').strip()
            parts = re.split(r'[/\-_\s\.]', prefix)
            for part in parts:
                if part and len(part) > 1:
                    keyword_categories.add(part)
        elif any(x in col_lower for x in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯']):
            # æå–å…³é”®è¯åˆ—å‰ç¼€
            for suffix in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯']:
                if col_lower.endswith(suffix):
                    prefix = col_lower[:-len(suffix)].strip()
                    parts = re.split(r'[/\-_\s\.]', prefix)
                    for part in parts:
                        if part and len(part) > 1:
                            keyword_categories.add(part)
                    break
    
    st.write(f"è¯†åˆ«åˆ°çš„å…³é”®è¯ç±»åˆ«: {keyword_categories}")
    
    # ç”Ÿæˆæ•°æ®è¡Œ
    rows = []
    
    # å‡½æ•°ï¼šæŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯åˆ—
    def find_matching_keyword_columns(campaign_name, df_survey, keyword_categories, keyword_columns, match_type):
        campaign_name_normalized = str(campaign_name).lower()
        
        # ç¡®å®šå…³é”®è¯ç±»åˆ«
        matched_categories = []
        for category in keyword_categories:
            if category and category in campaign_name_normalized:
                matched_categories.append(category)
        
        st.write(f"  åŒ¹é…çš„å…³é”®è¯ç±»åˆ«